{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Wrangling Lab**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **45** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will perform data wrangling tasks to prepare raw data for analysis. Data wrangling involves cleaning, transforming, and organizing data into a structured format suitable for analysis. This lab focuses on tasks like identifying inconsistencies, encoding categorical variables, and feature transformation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing this lab, you will be able to:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Identify and remove inconsistent data entries.\n",
    "\n",
    "- Encode categorical variables for analysis.\n",
    "\n",
    "- Handle missing values using multiple imputation strategies.\n",
    "\n",
    "- Apply feature scaling and transformation techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intsall the required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.3.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m147.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.3.1-cp312-cp312-manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m168.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.3.1 pandas-2.3.0 tzdata-2025.2\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.58.5-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (106 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m132.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (323 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.58.5-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m143.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m161.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.58.5 kiwisolver-1.4.8 matplotlib-3.10.3 pillow-11.3.0 pyparsing-3.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Import the necessary module.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>1.1 Import necessary libraries and load the dataset.</h5>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure the dataset is loaded correctly by displaying the first few rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ResponseId                      MainBranch                 Age  \\\n",
      "0           1  I am a developer by profession  Under 18 years old   \n",
      "1           2  I am a developer by profession     35-44 years old   \n",
      "2           3  I am a developer by profession     45-54 years old   \n",
      "3           4           I am learning to code     18-24 years old   \n",
      "4           5  I am a developer by profession     18-24 years old   \n",
      "\n",
      "            Employment RemoteWork   Check  \\\n",
      "0  Employed, full-time     Remote  Apples   \n",
      "1  Employed, full-time     Remote  Apples   \n",
      "2  Employed, full-time     Remote  Apples   \n",
      "3   Student, full-time        NaN  Apples   \n",
      "4   Student, full-time        NaN  Apples   \n",
      "\n",
      "                                    CodingActivities  \\\n",
      "0                                              Hobby   \n",
      "1  Hobby;Contribute to open-source projects;Other...   \n",
      "2  Hobby;Contribute to open-source projects;Other...   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                             EdLevel  \\\n",
      "0                          Primary/elementary school   \n",
      "1       Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
      "2    Master’s degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
      "3  Some college/university study without earning ...   \n",
      "4  Secondary school (e.g. American high school, G...   \n",
      "\n",
      "                                           LearnCode  \\\n",
      "0                             Books / Physical media   \n",
      "1  Books / Physical media;Colleague;On the job tr...   \n",
      "2  Books / Physical media;Colleague;On the job tr...   \n",
      "3  Other online resources (e.g., videos, blogs, f...   \n",
      "4  Other online resources (e.g., videos, blogs, f...   \n",
      "\n",
      "                                     LearnCodeOnline  ... JobSatPoints_6  \\\n",
      "0                                                NaN  ...            NaN   \n",
      "1  Technical documentation;Blogs;Books;Written Tu...  ...            0.0   \n",
      "2  Technical documentation;Blogs;Books;Written Tu...  ...            NaN   \n",
      "3  Stack Overflow;How-to videos;Interactive tutorial  ...            NaN   \n",
      "4  Technical documentation;Blogs;Written Tutorial...  ...            NaN   \n",
      "\n",
      "  JobSatPoints_7 JobSatPoints_8 JobSatPoints_9 JobSatPoints_10  \\\n",
      "0            NaN            NaN            NaN             NaN   \n",
      "1            0.0            0.0            0.0             0.0   \n",
      "2            NaN            NaN            NaN             NaN   \n",
      "3            NaN            NaN            NaN             NaN   \n",
      "4            NaN            NaN            NaN             NaN   \n",
      "\n",
      "  JobSatPoints_11           SurveyLength SurveyEase ConvertedCompYearly JobSat  \n",
      "0             NaN                    NaN        NaN                 NaN    NaN  \n",
      "1             0.0                    NaN        NaN                 NaN    NaN  \n",
      "2             NaN  Appropriate in length       Easy                 NaN    NaN  \n",
      "3             NaN               Too long       Easy                 NaN    NaN  \n",
      "4             NaN              Too short       Easy                 NaN    NaN  \n",
      "\n",
      "[5 rows x 114 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Stack Overflow survey data\n",
    "dataset_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"\n",
    "df = pd.read_csv(dataset_url)\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Explore the Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>2.1 Summarize the dataset by displaying the column data types, counts, and missing values.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 65437 entries, 0 to 65436\n",
      "Columns: 114 entries, ResponseId to JobSat\n",
      "dtypes: float64(13), int64(1), object(100)\n",
      "memory usage: 56.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>2.2 Generate basic statistics for numerical columns.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>CompTotal</th>\n",
       "      <th>WorkExp</th>\n",
       "      <th>JobSatPoints_1</th>\n",
       "      <th>JobSatPoints_4</th>\n",
       "      <th>JobSatPoints_5</th>\n",
       "      <th>JobSatPoints_6</th>\n",
       "      <th>JobSatPoints_7</th>\n",
       "      <th>JobSatPoints_8</th>\n",
       "      <th>JobSatPoints_9</th>\n",
       "      <th>JobSatPoints_10</th>\n",
       "      <th>JobSatPoints_11</th>\n",
       "      <th>ConvertedCompYearly</th>\n",
       "      <th>JobSat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>65437.00</td>\n",
       "      <td>3.374000e+04</td>\n",
       "      <td>29658.00</td>\n",
       "      <td>29324.00</td>\n",
       "      <td>29393.00</td>\n",
       "      <td>29411.00</td>\n",
       "      <td>29450.00</td>\n",
       "      <td>29448.00</td>\n",
       "      <td>29456.00</td>\n",
       "      <td>29456.00</td>\n",
       "      <td>29450.00</td>\n",
       "      <td>29445.00</td>\n",
       "      <td>23435.00</td>\n",
       "      <td>29126.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>32719.00</td>\n",
       "      <td>2.963841e+145</td>\n",
       "      <td>11.47</td>\n",
       "      <td>18.58</td>\n",
       "      <td>7.52</td>\n",
       "      <td>10.06</td>\n",
       "      <td>24.34</td>\n",
       "      <td>22.97</td>\n",
       "      <td>20.28</td>\n",
       "      <td>16.17</td>\n",
       "      <td>10.96</td>\n",
       "      <td>9.95</td>\n",
       "      <td>86155.29</td>\n",
       "      <td>6.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18890.18</td>\n",
       "      <td>5.444117e+147</td>\n",
       "      <td>9.17</td>\n",
       "      <td>25.97</td>\n",
       "      <td>18.42</td>\n",
       "      <td>21.83</td>\n",
       "      <td>27.09</td>\n",
       "      <td>27.02</td>\n",
       "      <td>26.11</td>\n",
       "      <td>24.85</td>\n",
       "      <td>22.91</td>\n",
       "      <td>21.78</td>\n",
       "      <td>186756.97</td>\n",
       "      <td>2.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16360.00</td>\n",
       "      <td>6.000000e+04</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>32712.00</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>32719.00</td>\n",
       "      <td>1.100000e+05</td>\n",
       "      <td>9.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>65000.00</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>49078.00</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>16.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>107971.50</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>65437.00</td>\n",
       "      <td>1.000000e+150</td>\n",
       "      <td>50.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>16256603.00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ResponseId      CompTotal   WorkExp  JobSatPoints_1  JobSatPoints_4  \\\n",
       "count    65437.00   3.374000e+04  29658.00        29324.00        29393.00   \n",
       "mean     32719.00  2.963841e+145     11.47           18.58            7.52   \n",
       "std      18890.18  5.444117e+147      9.17           25.97           18.42   \n",
       "min          1.00   0.000000e+00      0.00            0.00            0.00   \n",
       "25%      16360.00   6.000000e+04      4.00            0.00            0.00   \n",
       "50%      32719.00   1.100000e+05      9.00           10.00            0.00   \n",
       "75%      49078.00   2.500000e+05     16.00           22.00            5.00   \n",
       "max      65437.00  1.000000e+150     50.00          100.00          100.00   \n",
       "\n",
       "       JobSatPoints_5  JobSatPoints_6  JobSatPoints_7  JobSatPoints_8  \\\n",
       "count        29411.00        29450.00        29448.00        29456.00   \n",
       "mean            10.06           24.34           22.97           20.28   \n",
       "std             21.83           27.09           27.02           26.11   \n",
       "min              0.00            0.00            0.00            0.00   \n",
       "25%              0.00            0.00            0.00            0.00   \n",
       "50%              0.00           20.00           15.00           10.00   \n",
       "75%             10.00           30.00           30.00           25.00   \n",
       "max            100.00          100.00          100.00          100.00   \n",
       "\n",
       "       JobSatPoints_9  JobSatPoints_10  JobSatPoints_11  ConvertedCompYearly  \\\n",
       "count        29456.00         29450.00         29445.00             23435.00   \n",
       "mean            16.17            10.96             9.95             86155.29   \n",
       "std             24.85            22.91            21.78            186756.97   \n",
       "min              0.00             0.00             0.00                 1.00   \n",
       "25%              0.00             0.00             0.00             32712.00   \n",
       "50%              5.00             0.00             0.00             65000.00   \n",
       "75%             20.00            10.00            10.00            107971.50   \n",
       "max            100.00           100.00           100.00          16256603.00   \n",
       "\n",
       "         JobSat  \n",
       "count  29126.00  \n",
       "mean       6.94  \n",
       "std        2.09  \n",
       "min        0.00  \n",
       "25%        6.00  \n",
       "50%        7.00  \n",
       "75%        8.00  \n",
       "max       10.00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here\n",
    "df.select_dtypes(include='number').describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Identifying and Removing Inconsistencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>3.1 Identify inconsistent or irrelevant entries in specific columns (e.g., Country).</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['United States of America',\n",
       " 'United Kingdom of Great Britain and Northern Ireland',\n",
       " 'Canada',\n",
       " 'Norway',\n",
       " 'Uzbekistan',\n",
       " 'Serbia',\n",
       " 'Poland',\n",
       " 'Philippines',\n",
       " 'Bulgaria',\n",
       " 'Switzerland',\n",
       " 'India',\n",
       " 'Germany',\n",
       " 'Ireland',\n",
       " 'Italy',\n",
       " 'Ukraine',\n",
       " 'Australia',\n",
       " 'Brazil',\n",
       " 'Japan',\n",
       " 'Austria',\n",
       " 'Iran, Islamic Republic of...',\n",
       " 'France',\n",
       " 'Saudi Arabia',\n",
       " 'Romania',\n",
       " 'Turkey',\n",
       " 'Nepal',\n",
       " 'Algeria',\n",
       " 'Sweden',\n",
       " 'Netherlands',\n",
       " 'Croatia',\n",
       " 'Pakistan',\n",
       " 'Czech Republic',\n",
       " 'Republic of North Macedonia',\n",
       " 'Finland',\n",
       " 'Slovakia',\n",
       " 'Russian Federation',\n",
       " 'Greece',\n",
       " 'Israel',\n",
       " 'Belgium',\n",
       " 'Mexico',\n",
       " 'United Republic of Tanzania',\n",
       " 'Hungary',\n",
       " 'Argentina',\n",
       " 'Portugal',\n",
       " 'Sri Lanka',\n",
       " 'Latvia',\n",
       " 'China',\n",
       " 'Singapore',\n",
       " 'Lebanon',\n",
       " 'Spain',\n",
       " 'South Africa',\n",
       " 'Lithuania',\n",
       " 'Viet Nam',\n",
       " 'Dominican Republic',\n",
       " 'Indonesia',\n",
       " 'Kosovo',\n",
       " 'Morocco',\n",
       " 'Taiwan',\n",
       " 'Georgia',\n",
       " 'San Marino',\n",
       " 'Tunisia',\n",
       " 'Bangladesh',\n",
       " 'Nigeria',\n",
       " 'Liechtenstein',\n",
       " 'Denmark',\n",
       " 'Ecuador',\n",
       " 'Malaysia',\n",
       " 'Albania',\n",
       " 'Azerbaijan',\n",
       " 'Chile',\n",
       " 'Ghana',\n",
       " 'Peru',\n",
       " 'Bolivia',\n",
       " 'Egypt',\n",
       " 'Luxembourg',\n",
       " 'Montenegro',\n",
       " 'Cyprus',\n",
       " 'Paraguay',\n",
       " 'Kazakhstan',\n",
       " 'Slovenia',\n",
       " 'Jordan',\n",
       " 'Venezuela, Bolivarian Republic of...',\n",
       " 'Costa Rica',\n",
       " 'Jamaica',\n",
       " 'Thailand',\n",
       " 'Nicaragua',\n",
       " 'Myanmar',\n",
       " 'Republic of Korea',\n",
       " 'Rwanda',\n",
       " 'Bosnia and Herzegovina',\n",
       " 'Benin',\n",
       " 'El Salvador',\n",
       " 'Zimbabwe',\n",
       " 'Afghanistan',\n",
       " 'Estonia',\n",
       " 'Malta',\n",
       " 'Uruguay',\n",
       " 'Belarus',\n",
       " 'Colombia',\n",
       " 'Republic of Moldova',\n",
       " 'Isle of Man',\n",
       " 'Nomadic',\n",
       " 'New Zealand',\n",
       " 'Palestine',\n",
       " 'Armenia',\n",
       " 'United Arab Emirates',\n",
       " 'Maldives',\n",
       " 'Ethiopia',\n",
       " 'Fiji',\n",
       " 'Guatemala',\n",
       " 'Uganda',\n",
       " 'Turkmenistan',\n",
       " 'Mauritius',\n",
       " 'Kenya',\n",
       " 'Cuba',\n",
       " 'Gabon',\n",
       " 'Bahamas',\n",
       " 'South Korea',\n",
       " 'Iceland',\n",
       " 'Honduras',\n",
       " 'Hong Kong (S.A.R.)',\n",
       " \"Lao People's Democratic Republic\",\n",
       " 'Mongolia',\n",
       " 'Cambodia',\n",
       " 'Madagascar',\n",
       " 'Angola',\n",
       " 'Democratic Republic of the Congo',\n",
       " 'Syrian Arab Republic',\n",
       " 'Iraq',\n",
       " 'Namibia',\n",
       " 'Senegal',\n",
       " 'Kyrgyzstan',\n",
       " 'Zambia',\n",
       " 'Swaziland',\n",
       " \"Côte d'Ivoire\",\n",
       " 'Kuwait',\n",
       " 'Tajikistan',\n",
       " 'Burundi',\n",
       " 'Trinidad and Tobago',\n",
       " 'Mauritania',\n",
       " 'Sierra Leone',\n",
       " 'Panama',\n",
       " 'Somalia',\n",
       " 'North Korea',\n",
       " 'Dominica',\n",
       " 'Guyana',\n",
       " 'Togo',\n",
       " 'Oman',\n",
       " 'Barbados',\n",
       " 'Andorra',\n",
       " \"Democratic People's Republic of Korea\",\n",
       " 'Qatar',\n",
       " 'Sudan',\n",
       " 'Cameroon',\n",
       " 'Papua New Guinea',\n",
       " 'Bahrain',\n",
       " 'Yemen',\n",
       " 'Malawi',\n",
       " 'Burkina Faso',\n",
       " 'Congo, Republic of the...',\n",
       " 'Botswana',\n",
       " 'Guinea-Bissau',\n",
       " 'Mozambique',\n",
       " 'Central African Republic',\n",
       " 'Equatorial Guinea',\n",
       " 'Suriname',\n",
       " 'Belize',\n",
       " 'Libyan Arab Jamahiriya',\n",
       " 'Cape Verde',\n",
       " 'Brunei Darussalam',\n",
       " 'Bhutan',\n",
       " 'Guinea',\n",
       " 'Niger',\n",
       " 'Antigua and Barbuda',\n",
       " 'Mali',\n",
       " 'Samoa',\n",
       " 'Lesotho',\n",
       " 'Saint Kitts and Nevis',\n",
       " 'Monaco',\n",
       " 'Micronesia, Federated States of...',\n",
       " 'Haiti',\n",
       " nan,\n",
       " 'Nauru',\n",
       " 'Liberia',\n",
       " 'Chad',\n",
       " 'Djibouti',\n",
       " 'Solomon Islands']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here\n",
    "\n",
    "countries = df['Country'].unique().tolist()\n",
    "countries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canada\n"
     ]
    }
   ],
   "source": [
    "for c in countries:\n",
    "    if c == \"Canada\":\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes\n"
     ]
    }
   ],
   "source": [
    "if \"Canada\" in countries:\n",
    "        print(\"Yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No\n"
     ]
    }
   ],
   "source": [
    "if \"Jupiter\" in countries:\n",
    "        print(\"Yes\")\n",
    "else:\n",
    "    print('No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries.count('Japan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any('Canada' for word in countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "subCountries = ['Japan', 'Germany', 'France', 'Canada']\n",
    "if any(country for country in countries):\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canada\n",
      "Germany\n",
      "Japan\n",
      "France\n"
     ]
    }
   ],
   "source": [
    "for country in countries:\n",
    "    if country in subCountries:\n",
    "        print(country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_series = pd.Series(countries)\n",
    "\n",
    "country_series.loc[country_series.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Afghanistan', 'Albania', 'Algeria', 'Andorra', 'Angola', 'Antigua and Barbuda', 'Argentina', 'Armenia', 'Australia', 'Austria', 'Azerbaijan', 'Bahamas', 'Bahrain', 'Bangladesh', 'Barbados', 'Belarus', 'Belgium', 'Belize', 'Benin', 'Bhutan', 'Bolivia', 'Bosnia and Herzegovina', 'Botswana', 'Brazil', 'Brunei Darussalam', 'Bulgaria', 'Burkina Faso', 'Burundi', 'Cambodia', 'Cameroon', 'Canada', 'Cape Verde', 'Central African Republic', 'Chad', 'Chile', 'China', 'Colombia', 'Congo, Republic of the...', 'Costa Rica', 'Croatia', 'Cuba', 'Cyprus', 'Czech Republic', \"Côte d'Ivoire\", \"Democratic People's Republic of Korea\", 'Democratic Republic of the Congo', 'Denmark', 'Djibouti', 'Dominica', 'Dominican Republic', 'Ecuador', 'Egypt', 'El Salvador', 'Equatorial Guinea', 'Estonia', 'Ethiopia', 'Fiji', 'Finland', 'France', 'Gabon', 'Georgia', 'Germany', 'Ghana', 'Greece', 'Guatemala', 'Guinea', 'Guinea-Bissau', 'Guyana', 'Haiti', 'Honduras', 'Hong Kong (S.A.R.)', 'Hungary', 'Iceland', 'India', 'Indonesia', 'Iran, Islamic Republic of...', 'Iraq', 'Ireland', 'Isle of Man', 'Israel', 'Italy', 'Jamaica', 'Japan', 'Jordan', 'Kazakhstan', 'Kenya', 'Kosovo', 'Kuwait', 'Kyrgyzstan', \"Lao People's Democratic Republic\", 'Latvia', 'Lebanon', 'Lesotho', 'Liberia', 'Libyan Arab Jamahiriya', 'Liechtenstein', 'Lithuania', 'Luxembourg', 'Madagascar', 'Malawi', 'Malaysia', 'Maldives', 'Mali', 'Malta', 'Mauritania', 'Mauritius', 'Mexico', 'Micronesia, Federated States of...', 'Monaco', 'Mongolia', 'Montenegro', 'Morocco', 'Mozambique', 'Myanmar', 'Namibia', 'Nauru', 'Nepal', 'Netherlands', 'New Zealand', 'Nicaragua', 'Niger', 'Nigeria', 'Nomadic', 'North Korea', 'Norway', 'Oman', 'Pakistan', 'Palestine', 'Panama', 'Papua New Guinea', 'Paraguay', 'Peru', 'Philippines', 'Poland', 'Portugal', 'Qatar', 'Republic of Korea', 'Republic of Moldova', 'Republic of North Macedonia', 'Romania', 'Russian Federation', 'Rwanda', 'Saint Kitts and Nevis', 'Samoa', 'San Marino', 'Saudi Arabia', 'Senegal', 'Serbia', 'Sierra Leone', 'Singapore', 'Slovakia', 'Slovenia', 'Solomon Islands', 'Somalia', 'South Africa', 'South Korea', 'Spain', 'Sri Lanka', 'Sudan', 'Suriname', 'Swaziland', 'Sweden', 'Switzerland', 'Syrian Arab Republic', 'Taiwan', 'Tajikistan', 'Thailand', 'Togo', 'Trinidad and Tobago', 'Tunisia', 'Turkey', 'Turkmenistan', 'Uganda', 'Ukraine', 'United Arab Emirates', 'United Kingdom of Great Britain and Northern Ireland', 'United Republic of Tanzania', 'United States of America', 'Uruguay', 'Uzbekistan', 'Venezuela, Bolivarian Republic of...', 'Viet Nam', 'Yemen', 'Zambia', 'Zimbabwe']\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Clean the list first\n",
    "countries_cleaned = [country for country in countries if not (isinstance(country, float) and math.isnan(country))]\n",
    "\n",
    "# Now you can sort the cleaned list\n",
    "countries_cleaned.sort()\n",
    "\n",
    "print(countries_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>3.2 Standardize entries in columns like Country or EdLevel by mapping inconsistent values to a consistent format.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 65437 entries, 0 to 65436\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   CompTotal            33740 non-null  float64\n",
      " 1   WorkExp              29658 non-null  float64\n",
      " 2   JobSatPoints_1       29324 non-null  float64\n",
      " 3   JobSatPoints_4       29393 non-null  float64\n",
      " 4   JobSatPoints_5       29411 non-null  float64\n",
      " 5   JobSatPoints_6       29450 non-null  float64\n",
      " 6   JobSatPoints_7       29448 non-null  float64\n",
      " 7   JobSatPoints_8       29456 non-null  float64\n",
      " 8   JobSatPoints_9       29456 non-null  float64\n",
      " 9   JobSatPoints_10      29450 non-null  float64\n",
      " 10  JobSatPoints_11      29445 non-null  float64\n",
      " 11  ConvertedCompYearly  23435 non-null  float64\n",
      " 12  JobSat               29126 non-null  float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 6.5 MB\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "import numpy as np\n",
    "df_only_numbers = df.select_dtypes(include=float)\n",
    "df_only_numbers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 65437 entries, 0 to 65436\n",
      "Data columns (total 14 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   ResponseId           65437 non-null  float64\n",
      " 1   CompTotal            33740 non-null  float64\n",
      " 2   WorkExp              29658 non-null  float64\n",
      " 3   JobSatPoints_1       29324 non-null  float64\n",
      " 4   JobSatPoints_4       29393 non-null  float64\n",
      " 5   JobSatPoints_5       29411 non-null  float64\n",
      " 6   JobSatPoints_6       29450 non-null  float64\n",
      " 7   JobSatPoints_7       29448 non-null  float64\n",
      " 8   JobSatPoints_8       29456 non-null  float64\n",
      " 9   JobSatPoints_9       29456 non-null  float64\n",
      " 10  JobSatPoints_10      29450 non-null  float64\n",
      " 11  JobSatPoints_11      29445 non-null  float64\n",
      " 12  ConvertedCompYearly  23435 non-null  float64\n",
      " 13  JobSat               29126 non-null  float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 7.0 MB\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "import numpy as np\n",
    "df_only_numbers = df.select_dtypes(include=np.number)\n",
    "# df_only_numbers.info()\n",
    "\n",
    "df_normalized = pd.DataFrame()\n",
    "for col in df_only_numbers: \n",
    "    min_n = df_only_numbers[col].min()\n",
    "    max_n = df_only_numbers[col].max()\n",
    "\n",
    "    df_normalized[col] = (df_only_numbers[col] - min_n) / (max_n - min_n)\n",
    "\n",
    "\n",
    "df_normalized.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 65437 entries, 0 to 65436\n",
      "Data columns (total 14 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   ResponseId           65437 non-null  float64\n",
      " 1   CompTotal            33740 non-null  float64\n",
      " 2   WorkExp              29658 non-null  float64\n",
      " 3   JobSatPoints_1       29324 non-null  float64\n",
      " 4   JobSatPoints_4       29393 non-null  float64\n",
      " 5   JobSatPoints_5       29411 non-null  float64\n",
      " 6   JobSatPoints_6       29450 non-null  float64\n",
      " 7   JobSatPoints_7       29448 non-null  float64\n",
      " 8   JobSatPoints_8       29456 non-null  float64\n",
      " 9   JobSatPoints_9       29456 non-null  float64\n",
      " 10  JobSatPoints_10      29450 non-null  float64\n",
      " 11  JobSatPoints_11      29445 non-null  float64\n",
      " 12  ConvertedCompYearly  23435 non-null  float64\n",
      " 13  JobSat               29126 non-null  float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 7.0 MB\n"
     ]
    }
   ],
   "source": [
    "df_standardized = pd.DataFrame()\n",
    "\n",
    "for col in df_only_numbers.columns:\n",
    "    mean_n = df_only_numbers[col].mean()\n",
    "    stdev_n = df_only_numbers[col].std()\n",
    "\n",
    "    df_standardized[col] = (df_only_numbers[col] - mean_n) / stdev_n\n",
    "\n",
    "df_standardized.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_only_numbers.columns:\n",
    "    mean_n = df_only_numbers[col].mean()\n",
    "    stdev_n = df_only_numbers[col].std()\n",
    "\n",
    "    # THIS IS THE CRITICAL PART:\n",
    "    if stdev_n == 0:\n",
    "        # If standard deviation is 0, this block is executed.\n",
    "        # We ASSIGN 0.0 to the column. No division happens here.\n",
    "        df_standardized[col] = 0.0\n",
    "    else:\n",
    "        # If standard deviation is NOT 0, this block is executed.\n",
    "        # The division (df_only_numbers[col] - mean_n) / stdev_n happens here.\n",
    "        df_standardized[col] = (df_only_numbers[col] - mean_n) / stdev_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Encoding Categorical Variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>4.1 Encode the Employment column using one-hot encoding.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "\n",
    "employed_dummies = pd.get_dummies(df['Employment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 65437 entries, 0 to 65436\n",
      "Columns: 110 entries, Employed, full-time to Student, part-time;Retired\n",
      "dtypes: bool(110)\n",
      "memory usage: 6.9 MB\n"
     ]
    }
   ],
   "source": [
    "employed_dummies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Employed, full-time',\n",
       " 'Employed, full-time;Employed, part-time',\n",
       " 'Employed, full-time;Independent contractor, freelancer, or self-employed',\n",
       " 'Employed, full-time;Independent contractor, freelancer, or self-employed;Employed, part-time',\n",
       " 'Employed, full-time;Independent contractor, freelancer, or self-employed;Employed, part-time;Retired']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employed_dummies.columns.tolist()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Employed, full-time</th>\n",
       "      <th>Employed, full-time;Employed, part-time</th>\n",
       "      <th>Employed, full-time;Independent contractor, freelancer, or self-employed</th>\n",
       "      <th>Employed, full-time;Independent contractor, freelancer, or self-employed;Employed, part-time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Employed, full-time  Employed, full-time;Employed, part-time  \\\n",
       "0                 True                                    False   \n",
       "1                 True                                    False   \n",
       "2                 True                                    False   \n",
       "3                False                                    False   \n",
       "4                False                                    False   \n",
       "\n",
       "   Employed, full-time;Independent contractor, freelancer, or self-employed  \\\n",
       "0                                              False                          \n",
       "1                                              False                          \n",
       "2                                              False                          \n",
       "3                                              False                          \n",
       "4                                              False                          \n",
       "\n",
       "   Employed, full-time;Independent contractor, freelancer, or self-employed;Employed, part-time  \n",
       "0                                              False                                             \n",
       "1                                              False                                             \n",
       "2                                              False                                             \n",
       "3                                              False                                             \n",
       "4                                              False                                             "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employed_dummies.iloc[:5, :4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Handling Missing Values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>5.1 Identify columns with the highest number of missing values.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseId                 0\n",
       "MainBranch                 0\n",
       "Age                        0\n",
       "Employment                 0\n",
       "RemoteWork             10631\n",
       "                       ...  \n",
       "JobSatPoints_11        35992\n",
       "SurveyLength            9255\n",
       "SurveyEase              9199\n",
       "ConvertedCompYearly    42002\n",
       "JobSat                 36311\n",
       "Length: 114, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Write your code here\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>5.2 Impute missing values in numerical columns (e.g., `ConvertedCompYearly`) with the mean or median.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Write your code here\n",
    "\n",
    "df['ConvertedCompYearly'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConvertedCompYearly_median = df['ConvertedCompYearly'].median()\n",
    "\n",
    "df['ConvertedCompYearly'] = df['ConvertedCompYearly'].fillna(value=ConvertedCompYearly_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseId             0\n",
       "CompTotal              0\n",
       "WorkExp                0\n",
       "JobSatPoints_1         0\n",
       "JobSatPoints_4         0\n",
       "JobSatPoints_5         0\n",
       "JobSatPoints_6         0\n",
       "JobSatPoints_7         0\n",
       "JobSatPoints_8         0\n",
       "JobSatPoints_9         0\n",
       "JobSatPoints_10        0\n",
       "JobSatPoints_11        0\n",
       "ConvertedCompYearly    0\n",
       "JobSat                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_numbers = df.select_dtypes(include='number')\n",
    "# print(df_numbers.columns)\n",
    "\n",
    "\n",
    "for col in df_numbers.columns:\n",
    "    df_median = df_numbers[col].median()\n",
    "    df[col] = df[col].fillna(value=df_median)\n",
    "\n",
    "\n",
    "df.select_dtypes(include='number').isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method select_dtypes in module pandas.core.frame:\n",
      "\n",
      "select_dtypes(include=None, exclude=None) -> 'Self' method of pandas.core.frame.DataFrame instance\n",
      "    Return a subset of the DataFrame's columns based on the column dtypes.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    include, exclude : scalar or list-like\n",
      "        A selection of dtypes or strings to be included/excluded. At least\n",
      "        one of these parameters must be supplied.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame\n",
      "        The subset of the frame including the dtypes in ``include`` and\n",
      "        excluding the dtypes in ``exclude``.\n",
      "\n",
      "    Raises\n",
      "    ------\n",
      "    ValueError\n",
      "        * If both of ``include`` and ``exclude`` are empty\n",
      "        * If ``include`` and ``exclude`` have overlapping elements\n",
      "        * If any kind of string dtype is passed in.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.dtypes: Return Series with the data type of each column.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    * To select all *numeric* types, use ``np.number`` or ``'number'``\n",
      "    * To select strings you must use the ``object`` dtype, but note that\n",
      "      this will return *all* object dtype columns. With\n",
      "      ``pd.options.future.infer_string`` enabled, using ``\"str\"`` will\n",
      "      work to select all string columns.\n",
      "    * See the `numpy dtype hierarchy\n",
      "      <https://numpy.org/doc/stable/reference/arrays.scalars.html>`__\n",
      "    * To select datetimes, use ``np.datetime64``, ``'datetime'`` or\n",
      "      ``'datetime64'``\n",
      "    * To select timedeltas, use ``np.timedelta64``, ``'timedelta'`` or\n",
      "      ``'timedelta64'``\n",
      "    * To select Pandas categorical dtypes, use ``'category'``\n",
      "    * To select Pandas datetimetz dtypes, use ``'datetimetz'``\n",
      "      or ``'datetime64[ns, tz]'``\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame({'a': [1, 2] * 3,\n",
      "    ...                    'b': [True, False] * 3,\n",
      "    ...                    'c': [1.0, 2.0] * 3})\n",
      "    >>> df\n",
      "            a      b  c\n",
      "    0       1   True  1.0\n",
      "    1       2  False  2.0\n",
      "    2       1   True  1.0\n",
      "    3       2  False  2.0\n",
      "    4       1   True  1.0\n",
      "    5       2  False  2.0\n",
      "\n",
      "    >>> df.select_dtypes(include='bool')\n",
      "       b\n",
      "    0  True\n",
      "    1  False\n",
      "    2  True\n",
      "    3  False\n",
      "    4  True\n",
      "    5  False\n",
      "\n",
      "    >>> df.select_dtypes(include=['float64'])\n",
      "       c\n",
      "    0  1.0\n",
      "    1  2.0\n",
      "    2  1.0\n",
      "    3  2.0\n",
      "    4  1.0\n",
      "    5  2.0\n",
      "\n",
      "    >>> df.select_dtypes(exclude=['int64'])\n",
      "           b    c\n",
      "    0   True  1.0\n",
      "    1  False  2.0\n",
      "    2   True  1.0\n",
      "    3  False  2.0\n",
      "    4   True  1.0\n",
      "    5  False  2.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(df.select_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MainBranch              0\n",
       "Age                     0\n",
       "Employment              0\n",
       "RemoteWork              0\n",
       "Check                   0\n",
       "                       ..\n",
       "ProfessionalCloud       0\n",
       "ProfessionalQuestion    0\n",
       "Industry                0\n",
       "SurveyLength            0\n",
       "SurveyEase              0\n",
       "Length: 100, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_objects = df.select_dtypes(include='object')\n",
    "# print(df_objects.columns)\n",
    "\n",
    "\n",
    "for col in df_objects.columns:\n",
    "    df_mode = df_objects[col].mode()[0]\n",
    "    df[col] = df_objects[col].fillna(value=df_mode)\n",
    "\n",
    "\n",
    "df.select_dtypes(include='object').isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>5.3 Impute missing values in categorical columns (e.g., `RemoteWork`) with the most frequent value.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "\n",
    "RemoteWork_mode = df['RemoteWork'].mode()[0]\n",
    "\n",
    "df['RemoteWork']=df['RemoteWork'].fillna(value=RemoteWork_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Feature Scaling and Transformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>6.1 Apply Min-Max Scaling to normalize the `ConvertedCompYearly` column.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>6.2 Log-transform the ConvertedCompYearly column to reduce skewness.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_301/1262067236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['ConvertedCompYearly_log_transformed'] = np.log(df['ConvertedCompYearly'])\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "\n",
    "\n",
    "df['ConvertedCompYearly_log_transformed'] = np.log(df['ConvertedCompYearly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    65437.000000\n",
       "mean        10.975674\n",
       "std          0.855452\n",
       "min          0.000000\n",
       "25%         11.082143\n",
       "50%         11.082143\n",
       "75%         11.082143\n",
       "max         16.604010\n",
       "Name: ConvertedCompYearly_log_transformed, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ConvertedCompYearly_log_transformed'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>7.1 Create a new column `ExperienceLevel` based on the `YearsCodePro` column:</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     65437\n",
       "unique       52\n",
       "top           2\n",
       "freq      17995\n",
       "Name: YearsCodePro, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Write your code here\n",
    "\n",
    "df['YearsCodePro'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2\n",
       "1    17\n",
       "2    27\n",
       "3     2\n",
       "4     2\n",
       "Name: YearsCodePro, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['YearsCodePro'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2',\n",
       " '17',\n",
       " '27',\n",
       " '7',\n",
       " '11',\n",
       " '25',\n",
       " '12',\n",
       " '10',\n",
       " '3',\n",
       " 'Less than 1 year',\n",
       " '18',\n",
       " '37',\n",
       " '15',\n",
       " '20',\n",
       " '6',\n",
       " '16',\n",
       " '8',\n",
       " '14',\n",
       " '4',\n",
       " '45',\n",
       " '1',\n",
       " '24',\n",
       " '29',\n",
       " '5',\n",
       " '30',\n",
       " '26',\n",
       " '9',\n",
       " '33',\n",
       " '13',\n",
       " '35',\n",
       " '23',\n",
       " '22',\n",
       " '31',\n",
       " '19',\n",
       " '21',\n",
       " '28',\n",
       " '34',\n",
       " '32',\n",
       " '40',\n",
       " '50',\n",
       " '39',\n",
       " '44',\n",
       " '42',\n",
       " '41',\n",
       " '36',\n",
       " '38',\n",
       " 'More than 50 years',\n",
       " '43',\n",
       " '47',\n",
       " '48',\n",
       " '46',\n",
       " '49']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['YearsCodePro'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Converted Numeric Series:\n",
      "YearsCodePro\n",
      "0      2856\n",
      "1      2639\n",
      "2     17995\n",
      "3      4093\n",
      "4      3215\n",
      "5      3526\n",
      "6      2843\n",
      "7      2517\n",
      "8      2549\n",
      "9      1493\n",
      "10     3251\n",
      "11     1312\n",
      "12     1777\n",
      "13     1127\n",
      "14     1082\n",
      "15     1635\n",
      "16      946\n",
      "17      814\n",
      "18      867\n",
      "19      516\n",
      "20     1549\n",
      "21      380\n",
      "22      492\n",
      "23      448\n",
      "24      632\n",
      "25      998\n",
      "26      426\n",
      "27      380\n",
      "28      342\n",
      "29      196\n",
      "30      689\n",
      "31      106\n",
      "32      194\n",
      "33      132\n",
      "34      169\n",
      "35      285\n",
      "36      119\n",
      "37      104\n",
      "38      134\n",
      "39       54\n",
      "40      194\n",
      "41       51\n",
      "42       55\n",
      "43       37\n",
      "44       42\n",
      "45       56\n",
      "46       21\n",
      "47       10\n",
      "48       14\n",
      "49       11\n",
      "50       14\n",
      "51       50\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Data type after conversion: int64\n",
      "\n",
      "Binned Series:\n",
      "YearsCodePro\n",
      "<1 Year         2856\n",
      "1-5 Years      31468\n",
      "6-10 Years     12653\n",
      "11-20 Years    11625\n",
      "21-30 Years     4983\n",
      "31-50 Years     1802\n",
      "50+ Years         50\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "s=df['YearsCodePro']\n",
    "# Step 1 & 2: Define a mapping for non-numeric strings and convert\n",
    "def convert_experience_to_numeric(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan # Keep NaN as NaN\n",
    "    elif value == 'Less than 1 year':\n",
    "        return 0 # Or 0.5, depending on your interpretation\n",
    "    elif value == 'More than 50 years':\n",
    "        return 51 # Or 50, or a higher cap like 60, depending on your bins\n",
    "    else:\n",
    "        try:\n",
    "            return int(value)\n",
    "        except ValueError:\n",
    "            return np.nan # Handle any other unexpected non-numeric strings as NaN\n",
    "\n",
    "# Apply the conversion function to the Series\n",
    "s_numeric = s.apply(convert_experience_to_numeric)\n",
    "\n",
    "print(\"\\nConverted Numeric Series:\")\n",
    "print(s_numeric.value_counts(dropna=False).sort_index())\n",
    "print(f\"\\nData type after conversion: {s_numeric.dtype}\")\n",
    "\n",
    "# Now that it's numeric, you can use pd.cut()\n",
    "# Example: Binning the numeric experience\n",
    "bins = [-1, 0, 5, 10, 20, 30, 50, 100] # Adjusted bins to include 0 and 51+\n",
    "labels = ['<1 Year', '1-5 Years', '6-10 Years', '11-20 Years', '21-30 Years', '31-50 Years', '50+ Years']\n",
    "\n",
    "s_binned = pd.cut(s_numeric, bins=bins, labels=labels, right=True, include_lowest=True)\n",
    "\n",
    "print(\"\\nBinned Series:\")\n",
    "print(s_binned.value_counts(dropna=False).sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you:\n",
    "\n",
    "- Explored the dataset to identify inconsistencies and missing values.\n",
    "\n",
    "- Encoded categorical variables for analysis.\n",
    "\n",
    "- Handled missing values using imputation techniques.\n",
    "\n",
    "- Normalized and transformed numerical data to prepare it for analysis.\n",
    "\n",
    "- Engineered a new feature to enhance data interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "1e8e234f19fd098e27b0518a87f18de690e1c51f1d3263d5690927d19971251e"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
